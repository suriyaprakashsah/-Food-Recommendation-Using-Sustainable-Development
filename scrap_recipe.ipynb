{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3582f91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get('https://www.seriouseats.com/').content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for data in soup.find_all('a', {'class': \"global-nav__list-item-link\"}):\n",
    "    if str(data.text).strip() == 'Recipes' or str(data.text).strip() == 'World Cuisines':\n",
    "        links.append(data.get('href'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sublinks = []\n",
    "for link in links:\n",
    "    get_data = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
    "    for sub_data in get_data.find_all('a', {'class': \"comp mntl-card-list-items mntl-document-card mntl-card card\"}):\n",
    "        get_sublinks.append(sub_data.get('href'))\n",
    "links = links+get_sublinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = []\n",
    "for link in links:\n",
    "    get_data = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
    "    title = []\n",
    "    url = []\n",
    "    for des in get_data.find_all('span', {'class': \"card__title\"}):\n",
    "            title.append(str(des.text).strip())\n",
    "    for link in get_data.find_all('a',{'class':'comp card'}):\n",
    "           url.append(link['href']) \n",
    "    for index, (title, url) in enumerate(zip(title, url)):\n",
    "        get_datas = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
    "        try:\n",
    "            for rate in get_datas.find('div', {'class': \"comp aggregate-star-rating__count mntl-aggregate-rating mntl-text-block\"}):\n",
    "                rating = str(rate.text).replace(\"(\" ,\"\").strip(')').strip()        \n",
    "        except:\n",
    "                rating = 0\n",
    "        serving = 0\n",
    "        pre_time = 0\n",
    "        for tim in get_datas.find_all('div', {'class': \"loc total-time project-meta__total-time\"}):\n",
    "            pre_time =  tim.find('span', {'class': \"meta-text__data\"}).text\n",
    "        for serv in get_datas.find_all('div', {'class': \"loc recipe-serving project-meta__recipe-serving\"}):\n",
    "            serving =  serv.find('span', {'class': \"meta-text__data\"}).text\n",
    "            serving = [int(word) for word in serving.split() if word.isdigit()][-1]\n",
    "        ingre = ''\n",
    "        for inre in get_datas.find_all('ul', {'class': \"structured-ingredients__list text-passage\"}):\n",
    "            for val in inre.find_all('li', {'class': \"structured-ingredients__list-item\"}):\n",
    "                ingre+=str(val.text).strip()+','\n",
    "        try:\n",
    "            nutrition = get_datas.find('table', {'class': 'nutrition-info__table'}).text.split()\n",
    "            pro = nutrition[-2].replace('g', '')\n",
    "            carbo = nutrition[-4].replace('g', '')\n",
    "            fat = nutrition[-6].replace('g', '')\n",
    "            cal = nutrition[-8]\n",
    "        except:\n",
    "            pro = 0\n",
    "            carbo = 0\n",
    "            fat = 0\n",
    "            cal = 0\n",
    "\n",
    "\n",
    "        recipe.append({'Recipe': title, 'Url': url, 'Ingredients':ingre.rstrip(','), 'Ratings': rating, 'Serving': serving, \n",
    "                                       'Prepration_Time': pre_time, 'Calories': cal, 'Protein': pro, 'Carbohydrate': carbo,\n",
    "                                              'Fat': fat})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade7a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(recipe)\n",
    "df.to_csv('recipes_set2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('recipes_set2.csv')\n",
    "df1.drop_duplicates(inplace = True)\n",
    "df1.dropna(subset=['Ingredients'], inplace=True)\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181387ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('recipes.csv')\n",
    "df2.drop_duplicates(inplace = True)\n",
    "df2.dropna(subset=['Ingredients'], inplace=True)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.append(df2)\n",
    "df3.drop_duplicates(inplace = True)\n",
    "df3.to_csv('recipes_final.csv', index=False)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(requests.get('https://www.seriouseats.com/all-recipes-5117985').content, 'html.parser')\n",
    "\n",
    "links = []\n",
    "for data in soup.find_all('div', {'class': \"comp mntl-taxonomysc-article-list mntl-document-card-list mntl-card-list mntl-block\"}):\n",
    "    links.append(data.find('a', {'class': \"truncated-list__item-link\"}).get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a18b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sublinks = []\n",
    "for link in links:\n",
    "    get_data = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
    "    for data in get_data.find_all('div', {'class': \"truncated-list__item\"}):\n",
    "        get_sublinks.append(data.find('a', {'class': \"truncated-list__item-link\"}).get('href'))\n",
    "links = links+get_sublinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = []\n",
    "for link in links:\n",
    "    get_data = BeautifulSoup(requests.get(link).content, 'html.parser')\n",
    "    title = []\n",
    "    url = []\n",
    "    for des in get_data.find_all('span', {'class': \"card__title\"}):\n",
    "            title.append(str(des.text).strip())\n",
    "    for link in get_data.find_all('a',{'class':'comp card'}):\n",
    "           url.append(link['href']) \n",
    "    for index, (title, url) in enumerate(zip(title, url)):\n",
    "        get_datas = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
    "        try:\n",
    "            for rate in get_datas.find('div', {'class': \"comp aggregate-star-rating__count mntl-aggregate-rating mntl-text-block\"}):\n",
    "                rating = str(rate.text).replace(\"(\" ,\"\").strip(')').strip()        \n",
    "        except:\n",
    "                rating = 0\n",
    "        serving = 0\n",
    "        pre_time = 0\n",
    "        for tim in get_datas.find_all('div', {'class': \"loc total-time project-meta__total-time\"}):\n",
    "            pre_time =  tim.find('span', {'class': \"meta-text__data\"}).text\n",
    "        for serv in get_datas.find_all('div', {'class': \"loc recipe-serving project-meta__recipe-serving\"}):\n",
    "            serving =  serv.find('span', {'class': \"meta-text__data\"}).text\n",
    "            serving = [int(word) for word in serving.split() if word.isdigit()][-1]\n",
    "        ingre = ''\n",
    "        for inre in get_datas.find_all('ul', {'class': \"structured-ingredients__list text-passage\"}):\n",
    "            for val in inre.find_all('li', {'class': \"structured-ingredients__list-item\"}):\n",
    "                print(val.text)\n",
    "                ingre+=str(val.text).strip()+','\n",
    "        try:\n",
    "            nutrition = get_datas.find('table', {'class': 'nutrition-info__table'}).text.split()\n",
    "            pro = nutrition[-2].replace('g', '')\n",
    "            carbo = nutrition[-4].replace('g', '')\n",
    "            fat = nutrition[-6].replace('g', '')\n",
    "            cal = nutrition[-8]\n",
    "        except:\n",
    "            pro = 0\n",
    "            carbo = 0\n",
    "            fat = 0\n",
    "            cal = 0\n",
    "\n",
    "\n",
    "        recipe.append({'Recipe': title, 'Url': url, 'Ingredients':ingre.rstrip(','), 'Ratings': rating, 'Serving': serving, \n",
    "                                       'Prepration_Time': pre_time, 'Calories': cal, 'Protein': pro, 'Carbohydrate': carbo,\n",
    "                                              'Fat': fat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa43fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(recipe)\n",
    "df.to_csv('recipes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f1d219feaabc015129a80948c67f1a016282d5116f385a321ff14854deb6786"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
